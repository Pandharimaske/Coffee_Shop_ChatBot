{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pandhari/Desktop/Coffee_Shop_ChatBot/Python_Backend/Backend/experiments\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pandhari/Desktop/Coffee_Shop_ChatBot/Python_Backend/Backend\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pandhari/Desktop/Coffee_Shop_ChatBot/Python_Backend\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Backend.graph.coffee_shop_graph import build_coffee_shop_graph\n",
    "# build = build_coffee_shop_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image , display\n",
    "# display(Image(build.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Backend.utils.memory_manager import get_user_memory\n",
    "# from Backend.utils.summary_memory import get_summary , get_messages\n",
    "# user_id = 15\n",
    "# state = {\n",
    "#             \"user_memory\": None,\n",
    "#             \"messages\" : [] ,\n",
    "#             \"chat_summary\": \"\",\n",
    "#             \"user_input\": \"\",\n",
    "#             \"response_message\": None,\n",
    "#             \"decision\": None,\n",
    "#             \"target_agent\": None,\n",
    "#             \"order\": [],\n",
    "#             \"final_price\": None,\n",
    "#             \"memory_node\": False,\n",
    "#         }\n",
    "\n",
    "# state[\"user_input\"] = \"Hlo this is aski\"\n",
    "        \n",
    "# state[\"user_memory\"] = get_user_memory(user_id)\n",
    "# state[\"chat_summary\"] = get_summary(id=user_id)\n",
    "# state[\"messages\"] = get_messages(id = user_id)\n",
    "\n",
    "# config = {\n",
    "#         \"configurable\": {\n",
    "#         \"user_id\": user_id\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build.stream(state , config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ai/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from App.chatbot import get_bot_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting get_user_memory\n",
      "Done get_user_memory\n",
      "Starting get_summary\n",
      "Done get_summary\n",
      "Starting get_messages\n",
      "Done get_messages\n",
      "Starting get_order\n",
      "Started Get Order\n",
      "Done get_order\n",
      "updates=[OrderUpdateItem(name='Latte', set_quantity=2, delta_quantity=None), OrderUpdateItem(name='Samosa', set_quantity=None, delta_quantity=-1), OrderUpdateItem(name='Pastry', set_quantity=None, delta_quantity=1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ai/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Order\n",
      "Started Serializing Order\n",
      "{'response': \"Hi Pratik, I've updated your order as requested. You now have 2 Lattes, and I've replaced the Samosa with a pastry. Your total comes out to be ₹9.50. Would you like to pay with card or cash today?\", 'state': {'user_memory': UserMemory(name='Pratik', likes=[], dislikes=[], allergies=[], last_order=None, feedback=[], location=None), 'messages': [HumanMessage(content='make the order 2 Lattes and replace the Samosa with a pastry', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Pratik, I've updated your order as requested. You now have 2 Lattes, and I've replaced the Samosa with a pastry. Your total comes out to be ₹9.50. Would you like to pay with card or cash today?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='make the order 2', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Pratik, I see you've updated your order to just 2 items. However, it seems like there's been a misunderstanding. Since you didn't specify what the 2 items are, I'll need a bit more information from you. Could you please tell me what you'd like to order? Perhaps 2 Lattes like before? And would you like to add anything else to your order, or replace any items that we don't serve in our coffee shop?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='i want to order 1 Latte', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Pratik, I've got your order for 1 Latte, which will be $4.75. Shall I place the order for you? Would you like to pay with card or cash today, or would you like to add anything else to your order, perhaps a pastry to go with your Latte?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='i want to order 3 Latte', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Pratik, I've got your order for 3 Lattes, which will be $14.25. Shall I go ahead and place the order for you? Would you like to pay with card or cash today?\", additional_kwargs={}, response_metadata={})], 'chat_summary': '--- Summary of the conversation ---\\nHere is the updated summary:\\n\\nPratik has placed an order for 2 Lattes and a pastry, with the pastry replacing the originally ordered Samosa. The total cost of the order is ₹9.50, and payment options are being discussed.', 'user_input': 'make the order 2 Lattes and replace the Samosa with a pastry', 'response_message': \"Hi Pratik, I've updated your order as requested. You now have 2 Lattes, and I've replaced the Samosa with a pastry. Your total comes out to be ₹9.50. Would you like to pay with card or cash today?\", 'decision': <GuardDecisionType.allowed: 'allowed'>, 'target_agent': <AgentType.update_order_agent: 'update_order_agent'>, 'order': [{'name': 'Latte', 'quantity': 2, 'per_unit_price': 4.75, 'total_price': 9.5}, {'name': 'Pastry', 'quantity': 1, 'per_unit_price': 0.0, 'total_price': 0.0}], 'final_price': 9.5, 'memory_node': False}}\n"
     ]
    }
   ],
   "source": [
    "print(get_bot_response(user_input=\"make it 2\" , user_id=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Backend.utils.util import load_llm\n",
    "from Backend.schemas.state_schema import OrderUpdateState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = load_llm()\n",
    "llm = llm.with_structured_output(OrderUpdateState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderUpdateState(updates=[OrderUpdateItem(name='Latte', set_quantity=None, delta_quantity=1)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"add one more Latte \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
