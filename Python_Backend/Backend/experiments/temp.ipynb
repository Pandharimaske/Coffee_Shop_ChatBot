{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pandhari/Desktop/Coffee_Shop_ChatBot/Python_Backend/Backend/experiments\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pandhari/Desktop/Coffee_Shop_ChatBot/Python_Backend/Backend\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pandhari/Desktop/Coffee_Shop_ChatBot/Python_Backend\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ai/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from Backend.graph.coffee_shop_graph import build_coffee_shop_graph\n",
    "build = build_coffee_shop_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image , display\n",
    "# display(Image(build.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from App.chatbot import get_bot_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting get_user_memory\n",
      "Done get_user_memory\n",
      "Starting get_summary\n",
      "Done get_summary\n",
      "Starting get_messages\n",
      "Done get_messages\n",
      "Starting get_order\n",
      "Started Get Order\n",
      "Done get_order\n",
      "Saving Order\n",
      "Started Serializing Order\n",
      "{'response': \"Hi Pratik! I'm glad you asked about our WiFi! We do have free high-speed WiFi available at Merry's Way coffee shop. It's a great spot to relax and get some work done while enjoying your cappuccinos. \\n\\nIf you need any more information or if there's anything else I can assist you with, feel free to let me know!\", 'state': {'user_memory': UserMemory(name='Pratik', likes=[], dislikes=[], allergies=[], last_order=None, feedback=[], location=None), 'messages': [HumanMessage(content='Tell me about the WiFi availability at the shop.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Pratik! I'm glad you asked about our WiFi! We do have free high-speed WiFi available at Merry's Way coffee shop. It's a great spot to relax and get some work done while enjoying your cappuccinos. \\n\\nIf you need any more information or if there's anything else I can assist you with, feel free to let me know!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='tell me about your Cappuccino', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Pratik, I'm so sorry about the hiccup earlier. Let me tell you all about our Cappuccino - it's a classic combination of rich espresso, steamed milk, and a lovely layer of foam on top. I remember you've ordered it before and really enjoyed it. We've already got your order of two cappuccinos ready, but if you'd like to know more or make any changes, just let me know. By the way, would you like to enjoy your drinks here and take advantage of our free high-speed WiFi?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='tell me about your Cappuccino', additional_kwargs={}, response_metadata={}), AIMessage(content='Hi Pratik! My apologies, my menu seems to be having a little hiccup at the moment.\\n\\nBut of course, I remember your usual! Our cappuccino is that perfect, classic combination of rich espresso, steamed milk, and a lovely, airy layer of foam on top.\\n\\nWere you thinking of getting your usual two cappuccinos today, or just curious for a refresher?', additional_kwargs={}, response_metadata={}), HumanMessage(content='tell me about your Cappuccino', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Pratik! Great question. The cappuccino is a fantastic choice, and I see it's one of your go-to drinks!\\n\\nIt's that perfect, balanced mix of rich espresso, steamed milk, and a lovely, airy layer of foam on top. It's a true classic for a reason!\\n\\nJust to confirm, the price for one is $4.50.\\n\\nWere you thinking of getting your usual two, or just curious about the details today?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='coffees under 5 available?', additional_kwargs={}, response_metadata={}), AIMessage(content='Hi Pratik, my apologies! It seems my recommendation tool is having a little hiccup at the moment.\\n\\nHowever, I can certainly help with that! I know from your last order that our cappuccinos are $4.50 each, which fits perfectly under your $5 budget. Most of our standard brewed coffees and Americanos are also in that price range.\\n\\nWould you like me to add a cappuccino to your order, or were you curious about other options?', additional_kwargs={}, response_metadata={}), HumanMessage(content='is anything available under 10', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Pratik, my apologies! It seems my recommendation tool is having a little hiccup at the moment and isn't working correctly.\\n\\nHowever, I can certainly help you with that! I remember your previous order of two cappuccinos was $9.00, which fits right in. Most of our individual pastries and standard drinks are also under $10.\\n\\nIs there anything specific you're in the mood for today?\", additional_kwargs={}, response_metadata={})], 'chat_summary': '--- Summary of the conversation ---\\nUpdated summary:\\nUser, Pratik, expressed a desire to order two cappuccinos. The assistant confirmed the order and provided the total cost of $9.00, asking if they should proceed with the order.', 'user_input': 'Tell me about the WiFi availability at the shop.', 'response_message': \"Hi Pratik! I'm glad you asked about our WiFi! We do have free high-speed WiFi available at Merry's Way coffee shop. It's a great spot to relax and get some work done while enjoying your cappuccinos. \\n\\nIf you need any more information or if there's anything else I can assist you with, feel free to let me know!\", 'decision': <GuardDecisionType.allowed: 'allowed'>, 'target_agent': <AgentType.details_agent: 'details_agent'>, 'order': [{'name': 'cappuccino', 'quantity': 2, 'per_unit_price': 4.5, 'total_price': 9.0}], 'final_price': 9, 'memory_node': False}}\n"
     ]
    }
   ],
   "source": [
    "print(get_bot_response(user_input=\"tell me about wifi availability at shop\" , user_id=15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain-openai\n",
      "Version: 0.3.28\n",
      "Summary: An integration package connecting OpenAI and LangChain\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /opt/anaconda3/envs/ai/lib/python3.10/site-packages\n",
      "Requires: langchain-core, openai, tiktoken\n",
      "Required-by: langchain-pinecone\n"
     ]
    }
   ],
   "source": [
    "!pip show langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Backend.utils.memory_manager import get_user_memory\n",
    "from Backend.utils.summary_memory import get_summary , get_messages , get_order\n",
    "\n",
    "graph = build_coffee_shop_graph() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Get Order\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">ðŸš€ Starting graph stream...</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mðŸš€ Starting graph stream\u001b[0m\u001b[1;32m...\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items=[ProductItemInput(name='Latte', quantity=3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ai/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Order\n",
      "Started Serializing Order\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "âœ… <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Done.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "âœ… \u001b[1;32mDone.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import asyncio\n",
    "import json\n",
    "from rich import print\n",
    "\n",
    "async def test_graph_stream(user_input: str, user_id: int):\n",
    "    state = {\n",
    "        \"user_memory\": None,\n",
    "        \"messages\": [],\n",
    "        \"chat_summary\": \"\",\n",
    "        \"user_input\": \"\",\n",
    "        \"response_message\": None,\n",
    "        \"decision\": None,\n",
    "        \"target_agent\": None,\n",
    "        \"order\": [],\n",
    "        \"final_price\": None,\n",
    "        \"memory_node\": False,\n",
    "    }\n",
    "\n",
    "    state[\"user_input\"] = user_input\n",
    "    state[\"user_memory\"] = get_user_memory(user_id)\n",
    "    state[\"chat_summary\"] = get_summary(id=user_id)\n",
    "    state[\"messages\"] = get_messages(id=user_id)\n",
    "    state[\"order\"], state[\"final_price\"] = get_order(id=user_id)\n",
    "\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"user_id\": user_id\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(\"[bold green]ðŸš€ Starting graph stream...[/bold green]\\n\")\n",
    "\n",
    "    async for event in graph.astream(state, config=config):\n",
    "        if \"node\" in event:\n",
    "            node = event[\"node\"]\n",
    "            print(f\"[bold blue]ðŸ”§ Node running: {node}[/bold blue]\")\n",
    "        if \"at\" in event:\n",
    "            print(f\"[dim]ðŸ•’ {event['at']}[/dim]\")\n",
    "\n",
    "    print(\"\\nâœ… [bold green]Done.[/bold green]\")\n",
    "\n",
    "# Run it\n",
    "await test_graph_stream(\"I want to order it\", user_id=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
